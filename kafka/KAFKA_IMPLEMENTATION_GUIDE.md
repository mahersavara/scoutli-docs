# Kafka Implementation Guide - Step by Step

HÆ°á»›ng dáº«n chi tiáº¿t Ä‘á»ƒ báº¡n tá»± tay implement Kafka vÃ o project Scoutli tá»« Ä‘áº§u.

## ğŸ¯ Má»¥c tiÃªu há»c táº­p

Sau khi hoÃ n thÃ nh guide nÃ y, báº¡n sáº½:
- âœ… Hiá»ƒu cÃ¡ch Kafka hoáº¡t Ä‘á»™ng trong Quarkus
- âœ… Biáº¿t cÃ¡ch setup Kafka infrastructure
- âœ… Implement Producer Ä‘á»ƒ emit events
- âœ… Implement Consumer Ä‘á»ƒ xá»­ lÃ½ events
- âœ… Test end-to-end flow
- âœ… Debug vÃ  troubleshoot Kafka issues

## ğŸ“‹ Prerequisites

- [ ] Java 17+ installed
- [ ] Maven installed
- [ ] Docker & Docker Compose installed
- [ ] ÄÃ£ Ä‘á»c `KAFKA_QUARKUS_GUIDE.md` (lÃ½ thuyáº¿t cÆ¡ báº£n)

## ğŸ—ºï¸ Implementation Roadmap

```
Phase 1: Infrastructure Setup (30 phÃºt)
  â”œâ”€ Step 1: Setup Kafka vá»›i Docker
  â””â”€ Step 2: Verify Kafka is running

Phase 2: Simple Producer (45 phÃºt)
  â”œâ”€ Step 3: Add dependencies
  â”œâ”€ Step 4: Create Event model
  â”œâ”€ Step 5: Configure Producer
  â””â”€ Step 6: Implement & Test Producer

Phase 3: Simple Consumer (45 phÃºt)
  â”œâ”€ Step 7: Configure Consumer
  â”œâ”€ Step 8: Implement Consumer
  â””â”€ Step 9: Test Producer â†’ Consumer flow

Phase 4: Real Use Case (1 giá»)
  â”œâ”€ Step 10: Implement Comment Notification
  â””â”€ Step 11: End-to-end testing

Phase 5: Advanced Topics (bonus)
  â”œâ”€ Error handling
  â”œâ”€ Idempotency
  â””â”€ Monitoring
```

---

## Phase 1: Infrastructure Setup

### Step 1: Setup Kafka vá»›i Docker Compose

**Má»¥c tiÃªu:** Cháº¡y Kafka + Zookeeper locally Ä‘á»ƒ test.

**Báº¡n cáº§n lÃ m gÃ¬:**

1. Má»Ÿ file `microservices/docker-compose.yml`
2. ThÃªm 2 services: `zookeeper` vÃ  `kafka` vÃ o file

**HÆ°á»›ng dáº«n:**

```yaml
# ThÃªm vÃ o pháº§n services: (sau interaction-db)

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: scoutli-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - scoutli-net

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: scoutli-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    networks:
      - scoutli-net
```

**Giáº£i thÃ­ch:**
- `zookeeper`: Kafka cáº§n Zookeeper Ä‘á»ƒ quáº£n lÃ½ cluster metadata
- `KAFKA_ADVERTISED_LISTENERS`: Äá»‹a chá»‰ mÃ  clients sáº½ connect tá»›i
- `KAFKA_AUTO_CREATE_TOPICS_ENABLE`: Tá»± Ä‘á»™ng táº¡o topics khi Producer gá»­i message
- Port `9092`: Kafka broker port (standard)

**Test:**
```bash
cd microservices
docker-compose up -d zookeeper kafka
docker-compose ps
# Pháº£i tháº¥y zookeeper vÃ  kafka Ä‘ang running
```

**Checkpoint:** Náº¿u cáº£ 2 containers Ä‘á»u running, báº¡n Ä‘Ã£ pass Step 1! âœ…

---

### Step 2: Verify Kafka is Running

**Má»¥c tiÃªu:** Äáº£m báº£o Kafka hoáº¡t Ä‘á»™ng Ä‘Ãºng.

**Báº¡n cáº§n lÃ m gÃ¬:**

Kiá»ƒm tra logs Ä‘á»ƒ Ä‘áº£m báº£o Kafka Ä‘Ã£ start thÃ nh cÃ´ng:

```bash
# Xem logs cá»§a Kafka
docker-compose logs kafka

# TÃ¬m dÃ²ng nÃ y trong logs:
# "INFO [KafkaServer id=1] started"
```

Done

**Test nÃ¢ng cao (optional):**

DÃ¹ng Kafka CLI Ä‘á»ƒ test:

```bash
# Exec vÃ o Kafka container
docker exec -it scoutli-kafka bash

# List topics (ban Ä‘áº§u sáº½ trá»‘ng)
kafka-topics --list --bootstrap-server localhost:9092

# Táº¡o test topic
kafka-topics --create --topic test --bootstrap-server localhost:9092

# List láº¡i Ä‘á»ƒ xem topic vá»«a táº¡o
kafka-topics --list --bootstrap-server localhost:9092

# Exit
exit
```

**Checkpoint:** Náº¿u báº¡n tháº¥y logs "started" hoáº·c cÃ³ thá»ƒ list topics, pass Step 2! âœ…

---

## Phase 2: Simple Producer

### Step 3: Add Kafka Dependencies

**Má»¥c tiÃªu:** ThÃªm dependencies cáº§n thiáº¿t cho Kafka.

**Báº¡n cáº§n lÃ m gÃ¬:**

Chá»n 1 service Ä‘á»ƒ báº¯t Ä‘áº§u. MÃ¬nh recommend `scoutli-interaction-service` (service xá»­ lÃ½ Comments).

1. Má»Ÿ `microservices/scoutli-interaction-service/pom.xml`
2. ThÃªm dependency sau vÃ o `<dependencies>`:

```xml
<!-- Kafka Reactive Messaging -->
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>
</dependency>
```

**Giáº£i thÃ­ch:**
- `quarkus-smallrye-reactive-messaging-kafka`: Extension chÃ­nh Ä‘á»ƒ dÃ¹ng Kafka
- NÃ³ bao gá»“m: Kafka client, Reactive Messaging API, serializers

**Test:**
```bash
cd microservices/scoutli-interaction-service
mvn clean compile
# Pháº£i compile thÃ nh cÃ´ng, khÃ´ng cÃ³ error vá» dependency
```

**Checkpoint:** Náº¿u compile success, pass Step 3! âœ…

---

### Step 4: Create Event Model

**Má»¥c tiÃªu:** Táº¡o class Ä‘áº¡i diá»‡n cho event sáº½ gá»­i qua Kafka.

**Báº¡n cáº§n lÃ m gÃ¬:**

Táº¡o package vÃ  class má»›i:

**File:** `microservices/scoutli-interaction-service/src/main/java/com/scoutli/event/CommentCreatedEvent.java`

```java
package com.scoutli.event;

import java.time.LocalDateTime;

/**
 * Event Ä‘Æ°á»£c emit khi cÃ³ comment má»›i Ä‘Æ°á»£c táº¡o.
 * Event nÃ y sáº½ Ä‘Æ°á»£c gá»­i qua Kafka Ä‘á»ƒ cÃ¡c services khÃ¡c xá»­ lÃ½.
 */
public class CommentCreatedEvent {

    // TODO: ThÃªm cÃ¡c fields cáº§n thiáº¿t
    // Gá»£i Ã½: commentId, discoveryId, authorId, content, timestamp...

    public Long commentId;
    public Long discoveryId;
    public String authorEmail;
    public String content;
    public LocalDateTime timestamp;

    // TODO: Táº¡o constructor máº·c Ä‘á»‹nh (báº¯t buá»™c cho JSON deserialization)
    public CommentCreatedEvent() {
    }

    // TODO: Táº¡o constructor vá»›i params Ä‘á»ƒ dá»… khá»Ÿi táº¡o
    public CommentCreatedEvent(Long commentId, Long discoveryId,
                               String authorEmail, String content) {
        this.commentId = commentId;
        this.discoveryId = discoveryId;
        this.authorEmail = authorEmail;
        this.content = content;
        this.timestamp = LocalDateTime.now();
    }

    // TODO: Override toString() Ä‘á»ƒ dá»… debug
    @Override
    public String toString() {
        return "CommentCreatedEvent{" +
                "commentId=" + commentId +
                ", discoveryId=" + discoveryId +
                ", authorEmail='" + authorEmail + '\'' +
                '}';
    }
}
```

**Giáº£i thÃ­ch:**
- Event lÃ  POJO (Plain Old Java Object)
- Pháº£i cÃ³ **constructor máº·c Ä‘á»‹nh** (Jackson cáº§n Ä‘á»ƒ deserialize)
- Fields public Ä‘á»ƒ Jackson dá»… dÃ ng serialize/deserialize
- `toString()` giÃºp debug khi log

**CÃ¢u há»i tá»± kiá»ƒm tra:**
1. Táº¡i sao cáº§n constructor máº·c Ä‘á»‹nh?
   - *Tráº£ lá»i: Jackson deserializer cáº§n nÃ³ Ä‘á»ƒ táº¡o object tá»« JSON*

2. Event nÃ y chá»©a thÃ´ng tin gÃ¬?
   - *Tráº£ lá»i: Táº¥t cáº£ info cáº§n thiáº¿t Ä‘á»ƒ Consumer xá»­ lÃ½ mÃ  khÃ´ng cáº§n query DB*

**Checkpoint:** File compile Ä‘Æ°á»£c vÃ  cÃ³ constructor máº·c Ä‘á»‹nh? Pass Step 4! âœ…

---

### Step 5: Configure Producer

**Má»¥c tiÃªu:** Config Ä‘á»ƒ service cÃ³ thá»ƒ gá»­i events vÃ o Kafka.

**Báº¡n cáº§n lÃ m gÃ¬:**

Má»Ÿ file `microservices/scoutli-interaction-service/src/main/resources/application.properties`

ThÃªm config sau (vÃ o cuá»‘i file, sau pháº§n common configs):

```properties
# ==================== KAFKA CONFIGURATION ====================

# Kafka broker address
kafka.bootstrap.servers=localhost:9092

# ==================== PRODUCER: Comment Events ====================
# Channel name: comment-created-out (tÃªn nÃ y sáº½ dÃ¹ng trong code)
mp.messaging.outgoing.comment-created-out.connector=smallrye-kafka
mp.messaging.outgoing.comment-created-out.topic=comment-events
mp.messaging.outgoing.comment-created-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer
```

**Giáº£i thÃ­ch tá»«ng dÃ²ng:**

```properties
# Äá»‹a chá»‰ Kafka broker (localhost vÃ¬ cháº¡y Docker local)
kafka.bootstrap.servers=localhost:9092

# Config cho outgoing channel (Producer)
# Format: mp.messaging.outgoing.<channel-name>.<property>

mp.messaging.outgoing.comment-created-out.connector=smallrye-kafka
# Chá»‰ Ä‘á»‹nh dÃ¹ng Kafka connector

mp.messaging.outgoing.comment-created-out.topic=comment-events
# TÃªn topic trong Kafka (sáº½ tá»± Ä‘á»™ng táº¡o náº¿u chÆ°a cÃ³)

mp.messaging.outgoing.comment-created-out.value.serializer=...
# Serializer: chuyá»ƒn Java object â†’ JSON Ä‘á»ƒ gá»­i qua Kafka
```

**Naming convention:**
- Channel name: `comment-created-out` (tÃªn logic trong code)
- Topic name: `comment-events` (tÃªn tháº­t trong Kafka)
- `-out` suffix: Convention cho outgoing channels (Producer)

**Checkpoint:** Config Ä‘Ã£ thÃªm vÃ o application.properties? Pass Step 5! âœ…

---

### Step 6: Implement Producer in CommentService

**Má»¥c tiÃªu:** Viáº¿t code Ä‘á»ƒ emit event khi táº¡o comment.

**Báº¡n cáº§n lÃ m gÃ¬:**

Má»Ÿ file `microservices/scoutli-interaction-service/src/main/java/com/scoutli/service/CommentService.java`

**TODO 1: Inject Emitter**

ThÃªm vÃ o Ä‘áº§u class (sau cÃ¡c @Inject khÃ¡c):

```java
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;
import com.scoutli.event.CommentCreatedEvent;

// ... existing code ...

@Inject
@Channel("comment-created-out")  // TÃªn channel pháº£i khá»›p vá»›i config
Emitter<CommentCreatedEvent> eventEmitter;
```

**Giáº£i thÃ­ch:**
- `@Channel("comment-created-out")`: Link vá»›i config Ä‘Ã£ táº¡o á»Ÿ Step 5
- `Emitter<CommentCreatedEvent>`: Interface Ä‘á»ƒ gá»­i events
- Quarkus sáº½ tá»± Ä‘á»™ng inject Emitter Ä‘Ã£ config sáºµn

**TODO 2: Emit Event sau khi lÆ°u Comment**

TÃ¬m method `createComment()`, sau dÃ²ng `commentRepository.persist(comment);`, thÃªm:

```java
@Transactional
public CommentDTO createComment(Long discoveryId,
                                 CommentDTO.CreateRequest request,
                                 String userEmail) {
    // ... existing code: validate, create comment, persist ...

    commentRepository.persist(comment);

    // TODO: Emit event vÃ o Kafka
    CommentCreatedEvent event = new CommentCreatedEvent(
        comment.getId(),
        discoveryId,
        userEmail,
        request.content
    );

    eventEmitter.send(event);

    log.info("âœ… Comment created (ID: {}) and event emitted to Kafka", comment.getId());

    return toDTO(comment);
}
```

**Giáº£i thÃ­ch flow:**
1. LÆ°u comment vÃ o DB (transaction)
2. Táº¡o event object vá»›i data tá»« comment
3. Gá»­i event vÃ o Kafka qua Emitter (non-blocking)
4. Return response vá» FE ngay (khÃ´ng chá» event Ä‘Æ°á»£c xá»­ lÃ½)

**CÃ¢u há»i tá»± kiá»ƒm tra:**

1. Event Ä‘Æ°á»£c emit khi nÃ o?
   - *Sau khi comment Ä‘Ã£ lÆ°u vÃ o DB thÃ nh cÃ´ng*

2. Náº¿u emit event bá»‹ lá»—i, comment Ä‘Ã£ lÆ°u cÃ³ bá»‹ rollback khÃ´ng?
   - *KhÃ´ng, vÃ¬ emit lÃ  non-blocking vÃ  ngoÃ i transaction*

3. FE cÃ³ cáº§n chá» event Ä‘Æ°á»£c xá»­ lÃ½ khÃ´ng?
   - *KhÃ´ng, response tráº£ vá» ngay sau khi lÆ°u DB*

**Test:**

1. Start Kafka (náº¿u chÆ°a cháº¡y):
```bash
cd microservices
docker-compose up -d
```

2. Start interaction-service:
```bash
cd microservices/scoutli-interaction-service
mvn quarkus:dev
```

3. Táº¡o comment qua API (adjust theo API cá»§a báº¡n):
```bash
curl -X POST http://localhost:8083/api/comments \
  -H "Content-Type: application/json" \
  -d '{
    "discoveryId": 1,
    "content": "Great place to visit!"
  }'
```

4. Check logs, pháº£i tháº¥y:
```
âœ… Comment created (ID: 1) and event emitted to Kafka
```

5. Verify event trong Kafka:
```bash
docker exec -it scoutli-kafka bash

# Consumer Ä‘á»ƒ xem messages trong topic
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic comment-events --from-beginning

# Pháº£i tháº¥y JSON cá»§a event
```

**Checkpoint:** Náº¿u tháº¥y event trong Kafka topic, pass Step 6! âœ…ğŸ‰

---

## Phase 3: Simple Consumer

### Step 7: Configure Consumer

**Má»¥c tiÃªu:** Config Ä‘á»ƒ service cÃ³ thá»ƒ Ä‘á»c events tá»« Kafka.

**Báº¡n cáº§n lÃ m gÃ¬:**

Má»Ÿ láº¡i `application.properties`, thÃªm config consumer:

```properties
# ==================== CONSUMER: Comment Events ====================
# Channel name: comment-created-in (convention: -in suffix cho consumer)
mp.messaging.incoming.comment-created-in.connector=smallrye-kafka
mp.messaging.incoming.comment-created-in.topic=comment-events
mp.messaging.incoming.comment-created-in.value.deserializer=io.quarkus.kafka.client.serialization.ObjectMapperDeserializer

# Chá»‰ Ä‘á»‹nh class type cho deserializer
mp.messaging.incoming.comment-created-in.value.deserializer.type=com.scoutli.event.CommentCreatedEvent

# Consumer group ID (quan trá»ng!)
mp.messaging.incoming.comment-created-in.group.id=interaction-service

# Äá»c tá»« Ä‘áº§u topic khi consumer má»›i join
mp.messaging.incoming.comment-created-in.auto.offset.reset=earliest
```

**Giáº£i thÃ­ch:**

```properties
# Deserializer: chuyá»ƒn JSON tá»« Kafka â†’ Java object
value.deserializer=...ObjectMapperDeserializer

# Pháº£i nÃ³i cho deserializer biáº¿t convert sang class nÃ o
value.deserializer.type=com.scoutli.event.CommentCreatedEvent

# Consumer Group ID: Cá»±c ká»³ quan trá»ng!
group.id=interaction-service
# - CÃ¡c consumers cÃ¹ng group.id sáº½ chia nhau xá»­ lÃ½ messages (load balancing)
# - Má»—i message chá»‰ Ä‘Æ°á»£c 1 consumer trong group xá»­ lÃ½
# - Kafka track offset theo group.id

# auto.offset.reset=earliest
# - earliest: Äá»c tá»« Ä‘áº§u topic khi consumer má»›i
# - latest: Chá»‰ Ä‘á»c messages má»›i tá»« lÃºc consumer start
```

**CÃ¢u há»i quan trá»ng:**

1. Náº¿u 2 instances cÃ¹ng `group.id=interaction-service`, khi cÃ³ 1 event, máº¥y instance xá»­ lÃ½?
   - *Tráº£ lá»i: Chá»‰ 1 instance (Kafka load balance)*

2. Náº¿u 2 instances khÃ¡c `group.id`, khi cÃ³ 1 event, máº¥y instance xá»­ lÃ½?
   - *Tráº£ lá»i: Cáº¢ 2 instances (má»—i group nháº­n 1 copy)*

**Checkpoint:** Config Ä‘Ã£ thÃªm? Pass Step 7! âœ…

---

### Step 8: Implement Consumer

**Má»¥c tiÃªu:** Viáº¿t code Ä‘á»ƒ xá»­ lÃ½ events tá»« Kafka.

**Báº¡n cáº§n lÃ m gÃ¬:**

Táº¡o class má»›i Ä‘á»ƒ handle events:

**File:** `microservices/scoutli-interaction-service/src/main/java/com/scoutli/consumer/CommentEventConsumer.java`

```java
package com.scoutli.consumer;

import com.scoutli.event.CommentCreatedEvent;
import io.smallrye.reactive.messaging.annotations.Blocking;
import org.eclipse.microprofile.reactive.messaging.Incoming;
import jakarta.enterprise.context.ApplicationScoped;
import lombok.extern.slf4j.Slf4j;

@ApplicationScoped
@Slf4j
public class CommentEventConsumer {

    /**
     * Consumer xá»­ lÃ½ CommentCreatedEvent tá»« Kafka.
     *
     * @Incoming: Chá»‰ Ä‘á»‹nh channel name (pháº£i khá»›p config)
     * @Blocking: Xá»­ lÃ½ synchronously (khÃ´ng async)
     */
    @Incoming("comment-created-in")
    @Blocking
    public void handleCommentCreated(CommentCreatedEvent event) {

        log.info("ğŸ“¬ Received event from Kafka: {}", event);

        // TODO: Implement business logic
        // VD: Táº¡o notification, gá»­i email, update cache, etc.

        // BÃ¢y giá» chá»‰ log ra Ä‘á»ƒ test
        log.info("   - Comment ID: {}", event.commentId);
        log.info("   - Discovery ID: {}", event.discoveryId);
        log.info("   - Author: {}", event.authorEmail);
        log.info("   - Content: {}", event.content);
        log.info("   - Timestamp: {}", event.timestamp);

        log.info("âœ… Event processed successfully!");
    }
}
```

**Giáº£i thÃ­ch:**

**Annotations:**
- `@ApplicationScoped`: Bean sáº½ tá»“n táº¡i suá»‘t lifecycle cá»§a app
- `@Incoming("comment-created-in")`: Link vá»›i channel config á»Ÿ Step 7
- `@Blocking`: Method xá»­ lÃ½ synchronously, khÃ´ng return CompletionStage

**Method signature:**
```java
public void handleCommentCreated(CommentCreatedEvent event)
```
- Parameter type: `CommentCreatedEvent` - Quarkus tá»± Ä‘á»™ng deserialize JSON â†’ object
- Return type: `void` - Kafka sáº½ auto-commit offset sau khi method return (khÃ´ng throw exception)

**Processing:**
- ÄÆ¡n giáº£n log thÃ´ng tin event
- Trong thá»±c táº¿ sáº½ cÃ³ business logic: táº¡o notification, gá»­i email, etc.

**Alternative signatures (nÃ¢ng cao):**

```java
// Async processing
@Incoming("comment-created-in")
public CompletionStage<Void> handle(CommentCreatedEvent event) {
    return CompletableFuture.runAsync(() -> {
        // async processing
    });
}

// With metadata
@Incoming("comment-created-in")
public void handle(Message<CommentCreatedEvent> message) {
    CommentCreatedEvent event = message.getPayload();
    long offset = message.getMetadata(IncomingKafkaRecordMetadata.class)
                         .get().getOffset();
    // manual ack
    message.ack();
}
```

**Checkpoint:** Consumer class Ä‘Ã£ táº¡o? Pass Step 8! âœ…

---

### Step 9: Test Producer â†’ Consumer Flow

**Má»¥c tiÃªu:** Verify toÃ n bá»™ flow hoáº¡t Ä‘á»™ng end-to-end.

**Báº¡n cáº§n lÃ m gÃ¬:**

**1. Start infrastructure:**
```bash
cd microservices
docker-compose up -d
```

**2. Start service (dev mode):**
```bash
cd microservices/scoutli-interaction-service
mvn quarkus:dev
```

**3. Check logs khi start:**
TÃ¬m dÃ²ng confirm Kafka connected:
```
INFO  [io.sma.rea.mes.kafka] SRMCK18258: Kafka version: 3.x.x
INFO  [io.sma.rea.mes.kafka] SRMCK18259: Kafka commit-id: xxx
```

**4. Táº¡o comment Ä‘á»ƒ trigger event:**
```bash
curl -X POST http://localhost:8083/api/comments \
  -H "Content-Type: application/json" \
  -d '{
    "discoveryId": 1,
    "content": "Testing Kafka flow!"
  }'
```

**5. Observe logs:**

Báº¡n pháº£i tháº¥y 2 dÃ²ng logs:

```
âœ… Comment created (ID: 1) and event emitted to Kafka   <- Producer log
ğŸ“¬ Received event from Kafka: CommentCreatedEvent{...}  <- Consumer log
   - Comment ID: 1
   - Discovery ID: 1
   - Author: user@example.com
   - Content: Testing Kafka flow!
âœ… Event processed successfully!
```

**6. Verify trong Kafka (optional):**
```bash
docker exec -it scoutli-kafka bash

# Check topic exists
kafka-topics --list --bootstrap-server localhost:9092
# Should see: comment-events

# Check messages
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic comment-events --from-beginning

# Check consumer group
kafka-consumer-groups --bootstrap-server localhost:9092 --list
# Should see: interaction-service

# Check consumer group details
kafka-consumer-groups --bootstrap-server localhost:9092 \
  --describe --group interaction-service
```

**Troubleshooting:**

**Problem:** Consumer khÃ´ng nháº­n event
- Check `group.id` cÃ³ Ä‘Ãºng khÃ´ng
- Check topic name cÃ³ khá»›p giá»¯a producer vÃ  consumer khÃ´ng
- Restart service Ä‘á»ƒ consumer reconnect

**Problem:** Deserialize error
- Check `value.deserializer.type` cÃ³ Ä‘Ãºng full class name khÃ´ng
- Check Event class cÃ³ constructor máº·c Ä‘á»‹nh khÃ´ng

**Problem:** Connection refused
- Check Kafka Ä‘ang cháº¡y: `docker-compose ps`
- Check port 9092 cÃ³ available khÃ´ng: `netstat -an | grep 9092`

**Checkpoint:** Náº¿u tháº¥y cáº£ Producer vÃ  Consumer logs, pass Step 9! âœ…ğŸ‰

---

## Phase 4: Real Use Case - Comment Notification

### Step 10: Implement Notification Feature

**Má»¥c tiÃªu:** XÃ¢y dá»±ng tÃ­nh nÄƒng thá»±c táº¿: Khi cÃ³ comment má»›i, gá»­i notification cho owner cá»§a Discovery.

**Báº¡n cáº§n lÃ m gÃ¬:**

**TODO 1: Táº¡o Notification Entity (náº¿u chÆ°a cÃ³)**

Check xem Ä‘Ã£ cÃ³ `Notification` entity chÆ°a. Náº¿u chÆ°a, táº¡o má»›i:

**File:** `microservices/scoutli-interaction-service/src/main/java/com/scoutli/domain/entity/Notification.java`

```java
package com.scoutli.domain.entity;

import jakarta.persistence.*;
import lombok.Getter;
import lombok.Setter;
import java.time.LocalDateTime;

@Entity
@Table(name = "notifications")
@Getter
@Setter
public class Notification {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(nullable = false)
    private String userEmail;  // User sáº½ nháº­n notification

    @Column(nullable = false)
    private String type;  // "COMMENT", "RATING", etc.

    @Column(nullable = false, length = 500)
    private String message;

    private Long relatedId;  // ID cá»§a comment, rating, etc.

    private String relatedType;  // "COMMENT", "RATING"

    @Column(nullable = false)
    private Boolean isRead = false;

    @Column(nullable = false)
    private LocalDateTime createdAt = LocalDateTime.now();
}
```

**TODO 2: Create Flyway Migration**

**File:** `microservices/scoutli-interaction-service/src/main/resources/db/migration/V2.0.0__Create_Notifications_Table.sql`

```sql
CREATE TABLE notifications (
    id BIGSERIAL PRIMARY KEY,
    user_email VARCHAR(255) NOT NULL,
    type VARCHAR(50) NOT NULL,
    message VARCHAR(500) NOT NULL,
    related_id BIGINT,
    related_type VARCHAR(50),
    is_read BOOLEAN NOT NULL DEFAULT false,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_user_email (user_email),
    INDEX idx_created_at (created_at)
);
```

**TODO 3: Enhance Event to include Discovery Owner**

Váº¥n Ä‘á»: Consumer cáº§n biáº¿t owner cá»§a Discovery Ä‘á»ƒ táº¡o notification, nhÆ°ng event hiá»‡n táº¡i khÃ´ng cÃ³ thÃ´ng tin nÃ y.

**Giáº£i phÃ¡p:** ThÃªm field `discoveryOwnerEmail` vÃ o `CommentCreatedEvent`.

Update `CommentCreatedEvent.java`:

```java
public class CommentCreatedEvent {
    public Long commentId;
    public Long discoveryId;
    public String authorEmail;
    public String content;
    public String discoveryOwnerEmail;  // â† ThÃªm field nÃ y
    public LocalDateTime timestamp;

    public CommentCreatedEvent() {
    }

    public CommentCreatedEvent(Long commentId, Long discoveryId,
                               String authorEmail, String content,
                               String discoveryOwnerEmail) {  // â† Update constructor
        this.commentId = commentId;
        this.discoveryId = discoveryId;
        this.authorEmail = authorEmail;
        this.content = content;
        this.discoveryOwnerEmail = discoveryOwnerEmail;
        this.timestamp = LocalDateTime.now();
    }
}
```

**TODO 4: Update Producer Ä‘á»ƒ láº¥y Discovery Owner**

Trong `CommentService.createComment()`, trÆ°á»›c khi emit event:

```java
@Transactional
public CommentDTO createComment(Long discoveryId,
                                 CommentDTO.CreateRequest request,
                                 String userEmail) {
    // ... existing validation ...

    // TODO: Fetch Discovery Ä‘á»ƒ láº¥y owner email
    // CÃ¡ch 1: Call Discovery Service qua REST Client
    // CÃ¡ch 2: LÆ°u discovery owner trong Comment table (denormalization)
    // CÃ¡ch 3: Consumer query Discovery Service

    // Giáº£ sá»­ báº¡n cÃ³ DiscoveryServiceClient
    String discoveryOwnerEmail = discoveryServiceClient.getDiscoveryOwner(discoveryId);

    commentRepository.persist(comment);

    // Emit event vá»›i owner info
    CommentCreatedEvent event = new CommentCreatedEvent(
        comment.getId(),
        discoveryId,
        userEmail,
        request.content,
        discoveryOwnerEmail  // â† Owner email
    );

    eventEmitter.send(event);

    return toDTO(comment);
}
```

**CÃ¢u há»i tÆ° duy:**
- Náº¿u Discovery Service bá»‹ down lÃºc láº¥y owner, pháº£i lÃ m sao?
  - Option A: KhÃ´ng emit event (comment Ä‘Æ°á»£c táº¡o nhÆ°ng khÃ´ng cÃ³ notification)
  - Option B: Emit event nhÆ°ng khÃ´ng cÃ³ owner, Consumer sáº½ query sau
  - Option C: Store owner email trong Comment table luÃ´n (trade-off: data duplication)

Báº¡n chá»n approach nÃ o vÃ  táº¡i sao?

**TODO 5: Implement Notification Logic trong Consumer**

Update `CommentEventConsumer.handleCommentCreated()`:

```java
@ApplicationScoped
@Slf4j
public class CommentEventConsumer {

    @Inject
    EntityManager em;

    @Incoming("comment-created-in")
    @Blocking
    @Transactional  // â† ThÃªm transaction
    public void handleCommentCreated(CommentCreatedEvent event) {

        log.info("ğŸ“¬ Received CommentCreatedEvent: {}", event);

        // TODO: Validate - khÃ´ng táº¡o notification náº¿u author = owner
        if (event.authorEmail.equals(event.discoveryOwnerEmail)) {
            log.info("Skipping notification: author is the owner");
            return;
        }

        // TODO: Check idempotency - Ä‘Ã£ táº¡o notification cho comment nÃ y chÆ°a?
        long existingCount = (Long) em.createQuery(
            "SELECT COUNT(n) FROM Notification n WHERE n.relatedId = :commentId AND n.relatedType = 'COMMENT'"
        ).setParameter("commentId", event.commentId).getSingleResult();

        if (existingCount > 0) {
            log.info("Notification already exists for comment {}, skipping", event.commentId);
            return;
        }

        // TODO: Táº¡o notification
        Notification notification = new Notification();
        notification.setUserEmail(event.discoveryOwnerEmail);
        notification.setType("COMMENT");
        notification.setMessage(
            String.format("%s Ä‘Ã£ comment vÃ o Discovery cá»§a báº¡n: \"%s\"",
                event.authorEmail,
                truncate(event.content, 50))
        );
        notification.setRelatedId(event.commentId);
        notification.setRelatedType("COMMENT");
        notification.setIsRead(false);
        notification.setCreatedAt(LocalDateTime.now());

        em.persist(notification);

        log.info("âœ… Notification created for user {}", event.discoveryOwnerEmail);
    }

    private String truncate(String str, int maxLength) {
        if (str.length() <= maxLength) return str;
        return str.substring(0, maxLength) + "...";
    }
}
```

**Giáº£i thÃ­ch:**

1. **Idempotency check:** Äáº£m báº£o khÃ´ng táº¡o duplicate notifications náº¿u event Ä‘Æ°á»£c replay
2. **Business logic validation:** Skip náº¿u author = owner
3. **Message formatting:** Táº¡o message dá»… Ä‘á»c cho user

**Checkpoint:** Notification Ä‘Æ°á»£c táº¡o trong DB sau khi comment? Pass Step 10! âœ…

---

### Step 11: End-to-End Testing

**Má»¥c tiÃªu:** Test toÃ n bá»™ flow tá»« API call â†’ Event â†’ Notification.

**Test Scenarios:**

**Scenario 1: Happy Path**

```bash
# 1. Táº¡o Discovery (giáº£ sá»­ owner: alice@example.com)
# 2. User khÃ¡c (bob@example.com) comment vÃ o Discovery

curl -X POST http://localhost:8083/api/comments \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <bob-token>" \
  -d '{
    "discoveryId": 1,
    "content": "Amazing place!"
  }'

# 3. Check DB
SELECT * FROM notifications WHERE user_email = 'alice@example.com';
# Should have 1 notification: "bob@example.com Ä‘Ã£ comment vÃ o Discovery cá»§a báº¡n..."
```

**Scenario 2: Owner tá»± comment (khÃ´ng táº¡o notification)**

```bash
curl -X POST http://localhost:8083/api/comments \
  -H "Authorization: Bearer <alice-token>" \
  -d '{
    "discoveryId": 1,
    "content": "Thanks everyone!"
  }'

# Check logs: "Skipping notification: author is the owner"
# Check DB: khÃ´ng cÃ³ notification má»›i
```

**Scenario 3: Idempotency (replay event)**

```bash
# 1. Stop service
# 2. Kafka váº«n giá»¯ event (vÃ¬ retention policy)
# 3. Restart service
# 4. Consumer sáº½ Ä‘á»c láº¡i event tá»« last committed offset

# Check logs: "Notification already exists for comment X, skipping"
# Check DB: váº«n chá»‰ cÃ³ 1 notification (khÃ´ng duplicate)
```

**Scenario 4: Error Handling**

```bash
# Simulate error: Comment cÃ³ invalid discoveryOwnerEmail

# Event sáº½ retry theo config
# Náº¿u retry háº¿t váº«n fail â†’ Message bá»‹ stuck

# Solution: Implement error handling trong consumer
```

**Performance Testing:**

```bash
# Gá»­i 100 comments cÃ¹ng lÃºc
for i in {1..100}; do
  curl -X POST http://localhost:8083/api/comments \
    -H "Content-Type: application/json" \
    -d "{\"discoveryId\": 1, \"content\": \"Comment $i\"}" &
done

# Check logs: Táº¥t cáº£ events Ä‘Æ°á»£c xá»­ lÃ½
# Check DB: 100 notifications Ä‘Æ°á»£c táº¡o
# Check timing: Má»—i event xá»­ lÃ½ máº¥t bao lÃ¢u?
```

**Monitoring:**

```bash
# Check consumer lag (events chÆ°a xá»­ lÃ½)
docker exec scoutli-kafka \
  kafka-consumer-groups --bootstrap-server localhost:9092 \
  --describe --group interaction-service

# Output:
# GROUP             TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
# interaction-svc   comment-events  0          150             150             0

# LAG = 0: ÄÃ£ xá»­ lÃ½ háº¿t
# LAG > 0: CÃ²n events chÆ°a xá»­ lÃ½ (consumer cháº­m)
```

**Checkpoint:** Táº¥t cáº£ scenarios pass? Pass Step 11! âœ…ğŸ‰ğŸ‰ğŸ‰

---

## Phase 5: Advanced Topics (Bonus)

### Error Handling & Retry

**Problem:** Consumer throw exception khi xá»­ lÃ½ event.

**Options:**

**1. Fail Strategy:**
```properties
mp.messaging.incoming.comment-created-in.failure-strategy=fail
```
- Consumer dá»«ng láº¡i, cáº§n manual restart
- Use case: Critical errors cáº§n human intervention

**2. Ignore Strategy:**
```properties
mp.messaging.incoming.comment-created-in.failure-strategy=ignore
```
- Bá» qua message lá»—i, tiáº¿p tá»¥c xá»­ lÃ½ messages tiáº¿p theo
- Use case: Non-critical events, cÃ³ thá»ƒ máº¥t 1 vÃ i messages

**3. Dead Letter Queue:**
```properties
mp.messaging.incoming.comment-created-in.failure-strategy=dead-letter-queue
mp.messaging.incoming.comment-created-in.dead-letter-queue.topic=comment-events-dlq
```
- Gá»­i message lá»—i sang topic khÃ¡c
- Use case: Cáº§n reprocess failed messages sau

**Implementation:**

```java
@Incoming("comment-created-in")
@Blocking
@Transactional
public void handleCommentCreated(CommentCreatedEvent event) {
    try {
        // Business logic
        createNotification(event);

    } catch (ValidationException e) {
        // KhÃ´ng retry cho validation errors
        log.error("Validation error: {}", e.getMessage());
        // KhÃ´ng throw â†’ message bá»‹ skip

    } catch (Exception e) {
        // Retry cho cÃ¡c errors khÃ¡c
        log.error("Error processing event: {}", event, e);
        throw e;  // Kafka sáº½ retry
    }
}
```

---

### Monitoring & Observability

**1. Metrics:**

Add dependency:
```xml
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-micrometer-registry-prometheus</artifactId>
</dependency>
```

Metrics endpoint: `http://localhost:8083/q/metrics`

Key metrics:
- `kafka_consumer_records_consumed_total`
- `kafka_consumer_records_lag_max`
- `kafka_producer_record_send_total`

**2. Logging:**

```java
@Incoming("comment-created-in")
public void handle(Message<CommentCreatedEvent> message) {
    IncomingKafkaRecordMetadata metadata = message.getMetadata(IncomingKafkaRecordMetadata.class).get();

    log.info("Processing event from Kafka:");
    log.info("  Topic: {}", metadata.getTopic());
    log.info("  Partition: {}", metadata.getPartition());
    log.info("  Offset: {}", metadata.getOffset());
    log.info("  Timestamp: {}", metadata.getTimestamp());

    // Process...
}
```

**3. Health Checks:**

Quarkus tá»± Ä‘á»™ng expose health checks:
- `http://localhost:8083/q/health/live`
- `http://localhost:8083/q/health/ready`

Kafka health Ä‘Æ°á»£c include tá»± Ä‘á»™ng.

---

### Testing

**1. Unit Test vá»›i In-Memory:**

```xml
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-test-kafka-companion</artifactId>
    <scope>test</scope>
</dependency>
```

```java
@QuarkusTest
class CommentEventConsumerTest {

    @Inject
    @Channel("comment-created-in")
    Emitter<CommentCreatedEvent> emitter;

    @Test
    void testNotificationCreated() {
        // Emit test event
        CommentCreatedEvent event = new CommentCreatedEvent(
            1L, 1L, "bob@test.com", "Test", "alice@test.com"
        );
        emitter.send(event);

        // Wait vÃ  verify
        await().atMost(5, SECONDS).until(() -> {
            List<Notification> notifications =
                Notification.list("userEmail", "alice@test.com");
            return !notifications.isEmpty();
        });
    }
}
```

---

## ğŸ“ Tá»•ng káº¿t

**Báº¡n Ä‘Ã£ há»c Ä‘Æ°á»£c:**
- âœ… Setup Kafka infrastructure vá»›i Docker
- âœ… Configure Producer vÃ  Consumer trong Quarkus
- âœ… Implement event-driven architecture
- âœ… Handle serialization/deserialization
- âœ… Implement idempotency
- âœ… Error handling strategies
- âœ… Testing vÃ  monitoring

**Next Steps:**
1. Apply pattern nÃ y cho Discovery events (DiscoveryCreated, DiscoveryUpdated)
2. Implement Rating events
3. Add more consumers: Analytics, Search Indexer
4. Deploy Kafka cluster lÃªn Kubernetes (Strimzi)
5. Implement Schema Registry (Avro) cho enterprise use case

**Questions to reflect:**
1. Khi nÃ o nÃªn dÃ¹ng Kafka thay vÃ¬ REST API?
2. Trade-offs cá»§a event-driven architecture?
3. LÃ m sao Ä‘áº£m báº£o data consistency giá»¯a services?
4. CÃ¡ch monitor vÃ  debug distributed events?

ChÃºc báº¡n há»c tá»‘t! ğŸš€
